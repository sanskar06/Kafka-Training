version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:6.1.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:6.1.0
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_CREATE_TOPICS: "log:3:1"

  
  filebeat:
    image: docker.elastic.co/beats/filebeat:5.4.3
    mem_limit: 1g
    command: filebeat -e -strict.perms=false
    volumes:
      - "./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro"
      - "./logs:/logs"
    depends_on:
      - broker
    
    
  logstash:
    build: .
    user: root
    # volumes:

    #   - "./logstash.conf:/usr/share/logstash/pipeline/logstash.conf"

    #   - "./logstash.yml:/config/logstash.yml"

    # command: bin/logstash-plugin install logstash-input-kafka

    # command: logstash -f /usr/share/logstash/pipeline/logstash.conf
    environment:
      - XPACK_MONITORING_ENABLED=false
    depends_on:
      - broker
  postgres:
    image: postgres:12
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5432:5432"